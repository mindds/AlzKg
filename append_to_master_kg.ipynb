{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTFtbWLrRV3S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def append_to_master_kg(master_csv_path, additional_csv_paths):\n",
        "    \"\"\"\n",
        "    Appends a list of CSV files to a master AlzKG CSV file, mirroring each edge to match the PrimeKG format.\n",
        "\n",
        "    Parameters:\n",
        "    - master_csv_path: str, the path to the master AlzKG CSV file.\n",
        "    - additional_csv_paths: list, a list of paths to additional CSV files to append.\n",
        "\n",
        "    Returns:\n",
        "    - final_df: DataFrame, the combined DataFrame with mirrored edges.\n",
        "    \"\"\"\n",
        "    # Load the master AlzKG CSV file\n",
        "    kgraw = pd.read_csv(master_csv_path)\n",
        "\n",
        "    # Load and concatenate the additional CSV files, ignoring their headers\n",
        "    additional_dfs = [pd.read_csv(file_path, header=None, skiprows=1) for file_path in additional_csv_paths]\n",
        "    combined_df = pd.concat(additional_dfs, ignore_index=True)\n",
        "\n",
        "    # Assuming kgraw and additional CSVs share the same column structure\n",
        "    combined_df.columns = kgraw.columns\n",
        "\n",
        "    # Create a copy for mirroring\n",
        "    interchanged_df = combined_df.copy()\n",
        "\n",
        "    # Specify columns to interchange for mirroring\n",
        "    # Adjust the column names based on your specific CSV format\n",
        "    columns_to_interchange = ['id', 'type', 'name', 'source']\n",
        "    for col in columns_to_interchange:\n",
        "        # Adjust 'x_col' and 'y_col' to match your CSV's column naming pattern\n",
        "        interchanged_df[f'x_{col}'], interchanged_df[f'y_{col}'] = combined_df[f'y_{col}'], combined_df[f'x_{col}']\n",
        "\n",
        "    # Now concatenate kgraw with the original and mirrored dataframes\n",
        "    final_df = pd.concat([kgraw, combined_df, interchanged_df], ignore_index=True)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# Example usage:\n",
        "# Import the drive module from Google Colab for file access, mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = \"/content/drive/My Drive/primekg_files\"\n",
        "\n",
        "master_csv_path = f'{filepath}/kg_raw_orig_filtered.csv'\n",
        "\n",
        "additional_csv_paths = [\n",
        "    f'{filepath}/Ex_kg.csv',\n",
        "    f'{filepath}/In_kg.csv',\n",
        "    f'{filepath}/Oli_kg.csv',\n",
        "    f'{filepath}/Opc_kg.csv',\n",
        "    f'{filepath}/Mic_kg.csv',\n",
        "    f'{filepath}/Ast_kg.csv'\n",
        "]\n",
        "\n",
        "# Append the additional CSV files to the master CSV and mirror edges\n",
        "final_df = append_to_master_kg(master_csv_path, additional_csv_paths)\n",
        "\n",
        "# Save the final DataFrame to a new CSV file\n",
        "final_df.to_csv(f'{filepath}/kgraw_with_mathys.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def update_celltype_node_ids(cell_dict_csv_path, node_dict_csv_path, input_csv_path, output_csv_path):\n",
        "    \"\"\"\n",
        "    Creates dictionaries mapping node names to node IDs,\n",
        "    then reads the alzkg file and replaces 'tbd' in x_id/y_id with the correct IDs\n",
        "    Finally, it saves the updated data to a new CSV file.\n",
        "    This function can be called after processing a dataset from a single paper or after a set of papers.\n",
        "\n",
        "    :param cell_dict_csv_path: str. The file path for the latest cell_data_dict.csv\n",
        "    :param node_dict_csv_path: str. The file path for the nodes CSV file from primekg\n",
        "    :param input_csv_path: str. The alzkg file\n",
        "    :param output_csv_path: str. The file path to save the updated CSV file.\n",
        "    \"\"\"\n",
        "    # Function to create a dictionary from dict CSVs\n",
        "    def create_dict_from_csv(csv_path, index_col, value_col):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df.columns = df.columns.str.strip(' \"\\'')\n",
        "        mapping_dict = pd.Series(df[value_col].values, index=df[index_col]).to_dict()\n",
        "        # Clean up the dictionary\n",
        "        mapping_dict = {k: v.strip(' \"') for k, v in mapping_dict.items()}\n",
        "        return mapping_dict\n",
        "\n",
        "    # Function to replace 'tbd' in the alzkg CSV\n",
        "    def replace_tbd_with_id(row, cell_type_dict, node_dict):\n",
        "        if row['x_type'] == 'celltype/state' and row['x_id'] == 'tbd':\n",
        "            row['x_id'] = cell_type_dict.get(row['x_name'], row['x_id'])\n",
        "        elif row['x_type'] == 'gene/protein' and row['x_id'] == 'tbd':\n",
        "            row['x_id'] = node_dict.get(row['x_name'], row['x_id'])\n",
        "        if row['y_type'] == 'celltype/state' and row['y_id'] == 'tbd':\n",
        "            row['y_id'] = cell_type_dict.get(row['y_name'], row['y_id'])\n",
        "        elif row['y_type'] == 'gene/protein' and row['y_id'] == 'tbd':\n",
        "            row['y_id'] = node_dict.get(row['y_name'], row['y_id'])\n",
        "        return row\n",
        "\n",
        "    # 1. Read the CSV files and create dictionaries\n",
        "    cell_type_dict = create_dict_from_csv(cell_dict_csv_path, 'cell_type_state_data_dict', 'ID')\n",
        "    node_dict = create_dict_from_csv(node_dict_csv_path, 'node_name', 'node_id')\n",
        "\n",
        "    # 2. Read the alzkg CSV file and apply the function to replace 'tbd'\n",
        "    input_df = pd.read_csv(input_csv_path)\n",
        "    updated_df = input_df.apply(lambda row: replace_tbd_with_id(row, cell_type_dict, node_dict), axis=1)\n",
        "\n",
        "    # Save the updated dataframe to the provided CSV file path\n",
        "    updated_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    return f\"Updated file saved to {output_csv_path}\"\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Import the drive module from Google Colab for file access, mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = \"/content/drive/My Drive/primekg_files/\"\n",
        "update_celltype_node_ids(\n",
        "    filepath + 'cell_data_dict.csv',\n",
        "    filepath + 'nodes_filtered.csv',\n",
        "    filepath + 'kgraw_with_mathys_lau.csv',\n",
        "    filepath + 'final.csv'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Pkvn-6FzBs80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kwdpor6sjsd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
